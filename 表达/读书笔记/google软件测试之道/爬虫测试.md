# https://baijiahao.baidu.com/s?id=1715188874962552355&wfr=spider&for=pc
一、测试阶段

　　对于需要调用第三方平台(比如魔蝎)进行数据采集的流程，大家可能比较熟悉，在第三方的页面进行授权后，第三方会帮我们完成数据采集的任务，我们只需要坐等结果回调回来就行了。但是如果是要自己做爬虫，那么又是个怎样的过程呢。

　　其实爬虫和其它业务一样，也是有流程的，一般先触发创建任务，爬虫模块进行数据采集，采集完成后再对数据进行解析入库。对于授权爬虫，有SDK页面的也可以直接通过页面进行请求，有的就只能通过请求接口来实现了。还有一类爬虫，在后台配置好任务后会定期到网站爬取数据并更新数据库。当然还有其他很多交互逻辑，每一步都需要分析和评估。

　　所以我们可以先从创建任务的接口入手，把整个流程连通起来，在接口的响应中添加简单的校验，比如创建任务之后有任务编号，并且可以通过查询接口获取到该次任务的结果数据，再检验数据是否有入库、入库是否准确、是否会乱码等。从接口入手的好处是我们可以将爬虫任务进行自动化检验，检验数据是否可以创建、爬虫是否可以正常爬取、爬取的结果是否入库等。解析的逻辑、入库的准确需要关注，爬虫结果数据的入库关系到数据的分析和应用，对于数据分析来说，如果源头的数据就是错误的，那么不管分析结果如何都是没意义的了。


　　总结

　　1.接口测试，调用接口进行数据采集，测试爬虫流程;接口基本测试以及弱网络、接口安全、接口性能等。

　　2.针对场景，可以通过接口或者SDK进行测试，包括成功的爬取场景和失败的场景，比如无数据、无效数据。

　　3.解析入库测试，数据采集完成后解析和入库逻辑检验。

　　4.异常测试，主要针对系统间交互的处理逻辑，如失败的重试机制、服务间的容错机制等。

　　5.爬虫质量和效率，主要是根据整体设计和代码实现来分析爬虫的处理方式是否是高可用的。

　　二、线上阶段

　　爬虫一旦上线给其它业务方使用，可用性和可靠性是需要保证的。对爬虫来说，线上监控非常重要!不仅要保证提供出去的爬虫是可以正常跑的，还要保证当出现异常时，能够在最短的时间内解决，所以监控要从以下三方面着手：

　　1.通过线上跑接口脚本监控提供的接口可以正常使用，而不是等业务方连基本的接口都调不通再反馈回来再进行修复，成本就比较大了。主动调接口，判断程序是否正常，可以只进行校验接口能跑通，条件允许的话在线上跑真实数据并进行结果校验。

　　2.监控线上出现的异常情况，比如将创建任务失败、登录失败、数据采集失败、数据解析失败、回调失败、数据入库失败等情况实时监控并且同步邮件，收到异常情况时开发就要尽快排查是什么原因，第一时间发现并解决。

　　3.监控目标网站的情况，可以通过web自动化，监控目标网站是否可用、是否发生变化等。

　　对爬虫来说，稳定性是非常重要的，但是很多不可控因素都会导致爬虫成功率下降，我们可以通过做好监控和预防措施，当意外发生时将风险降到最低。